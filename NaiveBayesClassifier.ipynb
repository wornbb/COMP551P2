{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections as coll\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def string_to_ngrams(s, n):\n",
    "    text = str(s).decode('utf-8').lower()\n",
    "    text = text.replace(' ', '')\n",
    "    ngrams = nltk.ngrams([c for c in text], n)\n",
    "    return [''.join(g) for g in ngrams]\n",
    "\n",
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self,\n",
    "                 n_gram=1,\n",
    "                 multimap=True,\n",
    "                 count_threshold=0,\n",
    "                 use_uniform_prior=False,\n",
    "                 laplace_smoothing=1.):\n",
    "        self.n_gram = n_gram\n",
    "        self.multimap = multimap\n",
    "        self.count_threshold = count_threshold\n",
    "        self.use_uniform_prior = use_uniform_prior\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        W = pd.DataFrame({'X': [X], 'y': [y]})\n",
    "        \n",
    "        # Count features\n",
    "        counts = {}\n",
    "        for (xx, yy) in zip(X, y):\n",
    "            category = np.zeros(5)\n",
    "            category[yy] = 1\n",
    "            ngrams = string_to_ngrams(xx, self.n_gram)\n",
    "            if not self.multimap:\n",
    "                ngrams = list(set(ngrams))\n",
    "            for ngram in ngrams:\n",
    "                if ngram in counts:\n",
    "                    counts[ngram] = counts[ngram] + category\n",
    "                else:\n",
    "                    counts[ngram] = category\n",
    "        counts = pd.DataFrame(counts).transpose()\n",
    "\n",
    "        # Filter low counts\n",
    "        keep = counts.apply(lambda row: sum(row) >= self.count_threshold, axis = 1)\n",
    "        counts = counts[keep == 1]\n",
    "        \n",
    "        # Apply Laplace smoothing by adding a letter\n",
    "        counts[counts.columns[-5:]] += self.laplace_smoothing\n",
    "        \n",
    "        # Count the # of n-grams observed in each language.\n",
    "        class_counts = np.array(counts[counts.columns[-5:]].apply(lambda x: np.sum(x) * 1., axis = 0).values)\n",
    "        \n",
    "        # Define P(Y = y) as the proportion of n-grams observed in each language.\n",
    "        if self.use_uniform_prior:\n",
    "            class_priors = np.full(5, .1/5)\n",
    "        else:\n",
    "            class_priors = class_counts / np.sum(class_counts)\n",
    "            \n",
    "        self.likelihood_ = counts.div(class_counts)\n",
    "        self.counts_ = counts\n",
    "        self.class_priors_ = class_priors\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for obs in X:\n",
    "            levels = string_to_ngrams(obs, n = self.n_gram)\n",
    "            \n",
    "            joint_likelihood = np.full(5, 1.0)\n",
    "            # joint_likelihood_log = np.log(joint_likelihood)\n",
    "            \n",
    "            # Calculate joint probability\n",
    "            for level in levels:\n",
    "                if not level in self.likelihood_.index:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate likelihood for X\n",
    "                likelihood = self.likelihood_[self.likelihood_.index == level][:1].reset_index().values\n",
    "                likelihood = np.array(np.delete(likelihood, 0).astype(float))\n",
    "                \n",
    "                joint_likelihood = np.multiply(joint_likelihood, likelihood)\n",
    "                # joint_likelihood_log = joint_likelihood_log + np.log(likelihood)\n",
    "                \n",
    "            # Calculate joint likelihood * class prior\n",
    "            prop_posterior = np.multiply(joint_likelihood, self.class_priors_)\n",
    "            \n",
    "            # Calculate posterior probability\n",
    "            posterior = prop_posterior / np.sum(prop_posterior)\n",
    "            prediction = np.argmax(posterior)\n",
    "            \n",
    "            predictions = predictions + [prediction]\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def classify(self, inputs):\n",
    "        return\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.110701</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.079793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.017498</td>\n",
       "      <td>0.020092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.019786</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.034296</td>\n",
       "      <td>0.036165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.031829</td>\n",
       "      <td>0.039761</td>\n",
       "      <td>0.051094</td>\n",
       "      <td>0.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.091096</td>\n",
       "      <td>0.134303</td>\n",
       "      <td>0.131776</td>\n",
       "      <td>0.144532</td>\n",
       "      <td>0.080941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.001148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.015499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.011129</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.050394</td>\n",
       "      <td>0.010333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.072082</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.094719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>0.032564</td>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.023536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.048228</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.036165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.043555</td>\n",
       "      <td>0.044432</td>\n",
       "      <td>0.040420</td>\n",
       "      <td>0.022962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.030824</td>\n",
       "      <td>0.030201</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>0.039610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.050701</td>\n",
       "      <td>0.065237</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.088364</td>\n",
       "      <td>0.047072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.097279</td>\n",
       "      <td>0.061265</td>\n",
       "      <td>0.087452</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.067164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.029678</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>0.011841</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.062466</td>\n",
       "      <td>0.054768</td>\n",
       "      <td>0.030999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.053998</td>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.069527</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.040184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.066777</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.050733</td>\n",
       "      <td>0.058793</td>\n",
       "      <td>0.033295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>é</th>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ê</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>í</th>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ñ</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ó</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.006315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ô</th>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ö</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ú</th>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>û</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ü</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ý</th>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ą</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ć</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>č</th>\n",
       "      <td>0.006595</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ď</th>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ę</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.019518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ł</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ś</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.013203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>š</th>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ť</th>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ż</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.011481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ž</th>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>—</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>’</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>…</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   0.000824  0.001101  0.000869  0.002100  0.000574\n",
       "1   0.001237  0.003015  0.000869  0.001750  0.001148\n",
       "2   0.001237  0.002010  0.000760  0.002275  0.000574\n",
       "3   0.000412  0.001340  0.000760  0.001050  0.000574\n",
       "4   0.000824  0.000766  0.000435  0.002100  0.000574\n",
       "5   0.000412  0.001819  0.000760  0.001050  0.000574\n",
       "6   0.000412  0.001388  0.000543  0.001225  0.000574\n",
       "7   0.000412  0.001340  0.000217  0.001400  0.000574\n",
       "8   0.000412  0.000814  0.000435  0.000350  0.000574\n",
       "9   0.000412  0.001484  0.000435  0.000700  0.000574\n",
       "a   0.103875  0.077203  0.110701  0.065792  0.079793\n",
       "b   0.019373  0.011774  0.013036  0.017498  0.020092\n",
       "c   0.019786  0.033791  0.036502  0.034296  0.036165\n",
       "d   0.034213  0.031829  0.039761  0.051094  0.029851\n",
       "e   0.091096  0.134303  0.131776  0.144532  0.080941\n",
       "f   0.002885  0.011918  0.008039  0.014523  0.001148\n",
       "g   0.001237  0.009046  0.015752  0.023797  0.015499\n",
       "h   0.011129  0.011152  0.014449  0.050394  0.010333\n",
       "i   0.050289  0.072082  0.054318  0.086614  0.094719\n",
       "j   0.032564  0.014933  0.007061  0.003500  0.023536\n",
       "k   0.048228  0.002250  0.001521  0.016973  0.036165\n",
       "l   0.027617  0.043555  0.044432  0.040420  0.022962\n",
       "m   0.050289  0.030824  0.030201  0.032896  0.039610\n",
       "n   0.050701  0.065237  0.068441  0.088364  0.047072\n",
       "o   0.097279  0.061265  0.087452  0.032371  0.067164\n",
       "p   0.029678  0.032164  0.029549  0.013823  0.037313\n",
       "q   0.000412  0.012301  0.011841  0.000175  0.000574\n",
       "r   0.036274  0.059829  0.062466  0.054768  0.030999\n",
       "s   0.053998  0.077251  0.069527  0.063167  0.040184\n",
       "t   0.066777  0.065046  0.050733  0.058793  0.033295\n",
       "..       ...       ...       ...       ...       ...\n",
       "é   0.005359  0.012109  0.002064  0.000525  0.000574\n",
       "ê   0.000412  0.001962  0.000109  0.000175  0.000574\n",
       "í   0.003710  0.000048  0.004563  0.000175  0.000574\n",
       "ñ   0.000412  0.000048  0.000652  0.000175  0.000574\n",
       "ó   0.000412  0.000048  0.003042  0.000175  0.006315\n",
       "ô   0.001649  0.000239  0.000109  0.000175  0.000574\n",
       "ö   0.000412  0.000048  0.000109  0.002800  0.000574\n",
       "ú   0.004946  0.000048  0.000217  0.000175  0.000574\n",
       "û   0.000412  0.000287  0.000109  0.000175  0.000574\n",
       "ü   0.000412  0.000048  0.000109  0.004199  0.000574\n",
       "ý   0.003710  0.000048  0.000109  0.000175  0.000574\n",
       "ą   0.000412  0.000048  0.000109  0.000175  0.007463\n",
       "ć   0.000412  0.000048  0.000109  0.000175  0.007463\n",
       "č   0.006595  0.000048  0.000109  0.000175  0.000574\n",
       "ď   0.003710  0.000048  0.000109  0.000175  0.000574\n",
       "ę   0.000412  0.000048  0.000109  0.000175  0.019518\n",
       "ł   0.000412  0.000048  0.000109  0.000175  0.014925\n",
       "ś   0.000412  0.000048  0.000109  0.000175  0.013203\n",
       "š   0.004534  0.000048  0.000109  0.000175  0.000574\n",
       "ť   0.004122  0.000048  0.000109  0.000175  0.000574\n",
       "ż   0.000412  0.000048  0.000109  0.000175  0.011481\n",
       "ž   0.003710  0.000048  0.000109  0.000175  0.000574\n",
       "—   0.000412  0.000287  0.000109  0.000175  0.000574\n",
       "’   0.000412  0.003494  0.000109  0.000175  0.000574\n",
       "…   0.000412  0.000909  0.000109  0.000175  0.001722\n",
       "�   0.000412  0.001388  0.000109  0.000175  0.000574\n",
       "�   0.000412  0.000335  0.000109  0.000175  0.000574\n",
       "�   0.000412  0.000287  0.000109  0.000175  0.000574\n",
       "�   0.000412  0.000335  0.000109  0.000175  0.000574\n",
       "�   0.000412  0.002010  0.000109  0.000175  0.000574\n",
       "\n",
       "[79 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "X_train = pd.read_csv(\"data/train_set_x.csv\")['Text'].values\n",
    "Y_train = pd.read_csv(\"data/train_set_y.csv\")['Category'].values\n",
    "X_test  = pd.read_csv(\"data/test_set_x.csv\")['Text'].values\n",
    "nbayes = NaiveBayesClassifier()\n",
    "nbayes.set_params(n_gram=1,\n",
    "                  multimap=True,\n",
    "                  count_threshold=5,\n",
    "                  use_uniform_prior=False,\n",
    "                  laplace_smoothing=1.0)\n",
    "nbayes.fit(X_train[:1000], Y_train[:1000])\n",
    "nbayes.likelihood_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.   1.   3.   1.   1.]\n",
      " [  1.  56.   6.   2.   1.]\n",
      " [  1.   3.  13.   1.   1.]\n",
      " [  1.   1.   2.  15.   1.]\n",
      " [  1.   1.   1.   1.   5.]]\n",
      "0.752\n",
      "0.248\n"
     ]
    }
   ],
   "source": [
    "true_x = X_train[1000:1100]\n",
    "true_y = Y_train[1000:1100]\n",
    "pred_y = nbayes.predict(true_x)\n",
    "\n",
    "loss = np.full((5,5), 1.0)\n",
    "for i in range(len(pred_y)):\n",
    "    loss[pred_y[i], true_y[i]] += 1\n",
    "    \n",
    "TPR = loss.trace() / loss.sum()\n",
    "FNR = 1 - TPR\n",
    "\n",
    "print(loss)\n",
    "print(TPR)\n",
    "print(FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752\n",
      "0.248\n",
      "cv_n_gram\n",
      "1\n",
      "2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:115: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import random\n",
    "\n",
    "xx = X_train[:1000].copy()\n",
    "yy = Y_train[:1000].copy()\n",
    "\n",
    "\n",
    "TPR = loss.trace() / loss.sum()\n",
    "FNR = 1 - TPR\n",
    "print(TPR)\n",
    "print(FNR)\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_micro': 'recall_macro'}\n",
    "\n",
    "print(\"cv_n_gram\")\n",
    "cv_n_gram = None\n",
    "for i in range(1, 3 + 1):\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(n_gram=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_n_gram = pd.concat((cv_n_gram,\n",
    "                           a_mean.rename(\"n_gram={}\".format(i))), axis=1)\n",
    "\n",
    "print(\"cv_laplace_smoothing\")\n",
    "cv_laplace_smoothing = None\n",
    "for i in [1., 10., 100.]:\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(laplace_smoothing=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_laplace_smoothing = pd.concat((cv_laplace_smoothing,\n",
    "                                      a_mean.rename(\"laplace_smoothing={}\".format(i))), axis=1)\n",
    "    \n",
    "print(\"cv_count_threshold\")\n",
    "cv_count_threshold = None\n",
    "for i in [1., 10., 100.]:\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(count_threshold=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_count_threshold = pd.concat((cv_count_threshold,\n",
    "                                    a_mean.rename(\"count_threshold={}\".format(i))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cv_n_gram)\n",
    "print(cv_laplace_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
