{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self):\n",
    "        None\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        label_p = np.array(X[X.columns[-5:]].apply(lambda x: np.sum(x) * 1., axis = 0).values)\n",
    "        label_p = (label_p / np.sum(label_p))\n",
    "        \n",
    "        # \"confusion\" function: predicted in rows, true in cols\n",
    "        confusion = np.zeros((5,5), float)\n",
    "        \n",
    "        # loss matrix\n",
    "        #loss = np.full((5,5), 0., float)\n",
    "        #np.fill_diagonal(loss, 1.)\n",
    "        \n",
    "        for _, row in y.iterrows():\n",
    "            #print row['Text']\n",
    "            yi = [] + [c for c in str(row['Text'])]\n",
    "            ptotal = [1., 1., 1., 1., 1.]\n",
    "            for yil in yi:\n",
    "                score = None\n",
    "                if yil in X.index:\n",
    "                    score = X[X.index == yil][:1].reset_index().values\n",
    "                    score = np.delete(score, 0).astype(float)\n",
    "                    score = np.array(score)\n",
    "                else:\n",
    "                    # If no letter found, assume equally likelihood to have come out\n",
    "                    # of any of the labels.\n",
    "                    continue\n",
    "                p = score + np.array([1., 1., 1., 1., 1.])\n",
    "                # Obtain P(X = x | Y = y) by calculating per-category frequency\n",
    "                # of current letter.\n",
    "                p = p / label_p\n",
    "                # Obtain P(X = x | Y = y) / P(X = x) by calculating P(X = x) which\n",
    "                # is the marginal over Y.\n",
    "                p = p / p.sum().astype(float)\n",
    "                ptotal = np.multiply(ptotal, p)\n",
    "\n",
    "            # hack: divide all elements by max and set all elements < 1 to 0\n",
    "            # i.e. [0.1, 0.2, 0.3, 0.2, 0.2] -> [0.33, 0.66, 1, 0.66, 0.66] -> [0, 0, 1, 0, 0]\n",
    "            #ptotal = np.multiply(ptotal, prior_adj)\n",
    "            pred = np.divide(ptotal, np.amax(ptotal))\n",
    "            pred = np.around(pred).argmax()\n",
    "            confusion[pred, row['Category']] += 1\n",
    "            # print((pred, row['Category'], row['Text']))\n",
    "            category = np.zeros(5)\n",
    "            category[row['Category']] = 1\n",
    "            # print(total)\n",
    "            \n",
    "        print(confusion)\n",
    "        loss_score = (np.trace(confusion) / np.sum(confusion))\n",
    "        print(loss_score)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        return []\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  57.   31.   30.    6.    6.]\n",
      " [   1.  401.   55.    8.    1.]\n",
      " [   0.   58.  156.    1.    1.]\n",
      " [   1.   23.    8.  114.    2.]\n",
      " [   0.    0.    2.    0.   38.]]\n",
      "0.766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from NGramGenerator import *\n",
    "\n",
    "Xf = pd.read_csv(\"data/train_set_x.csv\")\n",
    "T  = pd.read_csv(\"data/train_set_y.csv\")\n",
    "X  = pd.merge(Xf, T, on = 'Id')\n",
    "Y  = pd.read_csv(\"data/test_set_x.csv\")\n",
    "\n",
    "ngram = NGramGenerator(1, True, 0, False)\n",
    "nbayes = NaiveBayesClassifier()\n",
    "\n",
    "\n",
    "p = Pipeline(\n",
    "    [( 'ngram', ngram )] +\n",
    "    [( 'nbayes', nbayes )]\n",
    ")\n",
    "\n",
    "#p.set_params(ngram__n=2)\n",
    "A = p.fit_transform(X[:3000], X[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
