{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 561kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/9c/1f/276bc3f421614062468cb1c9d695e6086d0c73d67ea363c501\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.5\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk as nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections as coll\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def string_to_ngrams(s, n):\n",
    "    # text = str(s).decode('utf-8').lower()\n",
    "    text = str(s).lower()\n",
    "    text = text.replace(' ', '')\n",
    "    ngrams = nltk.ngrams([c for c in text], n)\n",
    "    return [''.join(g) for g in ngrams]\n",
    "\n",
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self,\n",
    "                 n_gram=1,\n",
    "                 multimap=True,\n",
    "                 count_threshold=0,\n",
    "                 use_uniform_prior=False,\n",
    "                 laplace_smoothing=1.):\n",
    "        self.n_gram = n_gram\n",
    "        self.multimap = multimap\n",
    "        self.count_threshold = count_threshold\n",
    "        self.use_uniform_prior = use_uniform_prior\n",
    "        self.laplace_smoothing = laplace_smoothing\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        W = pd.DataFrame({'X': [X], 'y': [y]})\n",
    "        \n",
    "        # Count features\n",
    "        counts = {}\n",
    "        for (xx, yy) in zip(X, y):\n",
    "            category = np.zeros(5)\n",
    "            category[yy] = 1\n",
    "            ngrams = string_to_ngrams(xx, self.n_gram)\n",
    "            if not self.multimap:\n",
    "                ngrams = list(set(ngrams))\n",
    "            for ngram in ngrams:\n",
    "                if ngram in counts:\n",
    "                    counts[ngram] = counts[ngram] + category\n",
    "                else:\n",
    "                    counts[ngram] = category\n",
    "        counts = pd.DataFrame(counts).transpose()\n",
    "\n",
    "        # Filter low counts\n",
    "        keep = counts.apply(lambda row: sum(row) >= self.count_threshold, axis = 1)\n",
    "        counts = counts[keep == 1]\n",
    "        \n",
    "        # Apply Laplace smoothing by adding a letter\n",
    "        counts[counts.columns[-5:]] += self.laplace_smoothing\n",
    "        \n",
    "        # Count the # of n-grams observed in each language.\n",
    "        class_counts = np.array(counts[counts.columns[-5:]].apply(lambda x: np.sum(x) * 1., axis = 0).values)\n",
    "        \n",
    "        # Define P(Y = y) as the proportion of n-grams observed in each language.\n",
    "        if self.use_uniform_prior:\n",
    "            class_priors = np.full(5, .1/5)\n",
    "        else:\n",
    "            class_priors = class_counts / np.sum(class_counts)\n",
    "            \n",
    "        # self.likelihood_ = counts.div(class_counts)\n",
    "        self.likelihood_ = np.log(counts.div(class_counts)) ###\n",
    "        self.counts_ = counts\n",
    "        self.class_priors_ = class_priors\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        for obs in X:\n",
    "            levels = string_to_ngrams(obs, n = self.n_gram)\n",
    "            \n",
    "            # joint_likelihood = np.full(5, 1.0)\n",
    "            joint_likelihood = np.full(5, 0.)\n",
    "            \n",
    "            # Calculate joint probability\n",
    "            for level in levels:\n",
    "                if not level in self.likelihood_.index:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate likelihood for X\n",
    "                likelihood = self.likelihood_[self.likelihood_.index == level][:1].reset_index().values\n",
    "                likelihood = np.array(np.delete(likelihood, 0).astype(float))\n",
    "                \n",
    "                # joint_likelihood = np.multiply(joint_likelihood, likelihood)\n",
    "                joint_likelihood = joint_likelihood + likelihood\n",
    "                \n",
    "            # Calculate joint likelihood * class prior\n",
    "            prop_posterior = np.multiply(joint_likelihood, self.class_priors_)\n",
    "            \n",
    "            # Calculate posterior probability\n",
    "            posterior = prop_posterior # / np.sum(prop_posterior)\n",
    "            prediction = np.argmax(posterior)\n",
    "            \n",
    "            predictions = predictions + [prediction]\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def classify(self, inputs):\n",
    "        return\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.114194</td>\n",
       "      <td>0.075716</td>\n",
       "      <td>0.109322</td>\n",
       "      <td>0.070641</td>\n",
       "      <td>0.091656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.018406</td>\n",
       "      <td>0.012466</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>0.019829</td>\n",
       "      <td>0.018760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.022866</td>\n",
       "      <td>0.035021</td>\n",
       "      <td>0.038695</td>\n",
       "      <td>0.039057</td>\n",
       "      <td>0.039805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.035085</td>\n",
       "      <td>0.029505</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.047375</td>\n",
       "      <td>0.032272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.096091</td>\n",
       "      <td>0.135673</td>\n",
       "      <td>0.129296</td>\n",
       "      <td>0.141005</td>\n",
       "      <td>0.086474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.011488</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>0.015227</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0.011953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>0.058611</td>\n",
       "      <td>0.010339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.057854</td>\n",
       "      <td>0.069550</td>\n",
       "      <td>0.055196</td>\n",
       "      <td>0.085988</td>\n",
       "      <td>0.087864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>0.026293</td>\n",
       "      <td>0.014805</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.028383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.040577</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.028483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.036484</td>\n",
       "      <td>0.045008</td>\n",
       "      <td>0.045356</td>\n",
       "      <td>0.041429</td>\n",
       "      <td>0.017452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.050849</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>0.030625</td>\n",
       "      <td>0.029981</td>\n",
       "      <td>0.038839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.055507</td>\n",
       "      <td>0.065749</td>\n",
       "      <td>0.066451</td>\n",
       "      <td>0.088729</td>\n",
       "      <td>0.051292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.089253</td>\n",
       "      <td>0.062853</td>\n",
       "      <td>0.090811</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>0.071518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.030754</td>\n",
       "      <td>0.031139</td>\n",
       "      <td>0.029256</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.028268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.038225</td>\n",
       "      <td>0.061671</td>\n",
       "      <td>0.059046</td>\n",
       "      <td>0.058276</td>\n",
       "      <td>0.035238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.051757</td>\n",
       "      <td>0.078814</td>\n",
       "      <td>0.071191</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.042367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.056036</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>0.050102</td>\n",
       "      <td>0.060043</td>\n",
       "      <td>0.041756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>️</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>�</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   0.001344  0.001753  0.001752  0.001522  0.000093\n",
       "1   0.001772  0.002259  0.001526  0.001774  0.000084\n",
       "2   0.001578  0.001910  0.001180  0.001220  0.000074\n",
       "3   0.001046  0.001202  0.000818  0.000781  0.000061\n",
       "4   0.000723  0.000963  0.000624  0.000420  0.000039\n",
       "5   0.000850  0.001399  0.000721  0.000559  0.000063\n",
       "6   0.000602  0.001318  0.000605  0.000625  0.000039\n",
       "7   0.000550  0.001704  0.000566  0.000431  0.000035\n",
       "8   0.000514  0.000851  0.000534  0.000290  0.000032\n",
       "9   0.000363  0.001270  0.000595  0.000377  0.000030\n",
       "a   0.114194  0.075716  0.109322  0.070641  0.091656\n",
       "b   0.018406  0.012466  0.013722  0.019829  0.018760\n",
       "c   0.022866  0.035021  0.038695  0.039057  0.039805\n",
       "d   0.035085  0.029505  0.039176  0.047375  0.032272\n",
       "e   0.096091  0.135673  0.129296  0.141005  0.086474\n",
       "f   0.002135  0.011488  0.007653  0.013842  0.001542\n",
       "g   0.002156  0.008784  0.015227  0.023658  0.011953\n",
       "h   0.017000  0.012251  0.016382  0.058611  0.010339\n",
       "i   0.057854  0.069550  0.055196  0.085988  0.087864\n",
       "j   0.026293  0.014805  0.006286  0.004424  0.028383\n",
       "k   0.040577  0.002045  0.002670  0.013812  0.028483\n",
       "l   0.036484  0.045008  0.045356  0.041429  0.017452\n",
       "m   0.050849  0.030423  0.030625  0.029981  0.038839\n",
       "n   0.055507  0.065749  0.066451  0.088729  0.051292\n",
       "o   0.089253  0.062853  0.090811  0.033082  0.071518\n",
       "p   0.030754  0.031139  0.029256  0.011573  0.028268\n",
       "q   0.000081  0.011777  0.012580  0.000195  0.000035\n",
       "r   0.038225  0.061671  0.059046  0.058276  0.035238\n",
       "s   0.051757  0.078814  0.071191  0.063116  0.042367\n",
       "t   0.056036  0.065845  0.050102  0.060043  0.041756\n",
       "..       ...       ...       ...       ...       ...\n",
       "�   0.000017  0.000022  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000019  0.000007  0.000022\n",
       "�   0.000017  0.000007  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000006  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000007  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000012  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000108  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000159  0.000006  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000042  0.000005  0.000007  0.000022\n",
       "�   0.000017  0.000030  0.000005  0.000007  0.000022\n",
       "�   0.000017  0.000107  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000013  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000018  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000039  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000013  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000123  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000025  0.000005  0.000007  0.000022\n",
       "�   0.000017  0.000041  0.000005  0.000007  0.000022\n",
       "�   0.000017  0.000376  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000049  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000008  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000012  0.000004  0.000007  0.000022\n",
       "�   0.000017  0.000011  0.000004  0.000007  0.000022\n",
       "   0.000017  0.000002  0.000004  0.000039  0.000022\n",
       "️   0.000017  0.000019  0.000005  0.000007  0.000022\n",
       "�   0.000017  0.002136  0.000071  0.000007  0.000022\n",
       "\n",
       "[157 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "X_train = pd.read_csv(\"data/train_set_x.csv\")['Text'].values\n",
    "Y_train = pd.read_csv(\"data/train_set_y.csv\")['Category'].values\n",
    "X_test  = pd.read_csv(\"data/test_set_x.csv\")['Text'].values\n",
    "nbayes = NaiveBayesClassifier()\n",
    "nbayes.set_params(n_gram=1,\n",
    "                  multimap=True,\n",
    "                  count_threshold=25,\n",
    "                  use_uniform_prior=False,\n",
    "                  laplace_smoothing=10.0)\n",
    "nbayes.fit(X_train, Y_train)\n",
    "nbayes.likelihood_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276517"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbayes.likelihood_)\n",
    "len(X_test)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   2.   2.   1.   2.]\n",
      " [  1.  42.   6.   3.   1.]\n",
      " [  1.   9.  12.   2.   1.]\n",
      " [  1.   4.   4.   8.   2.]\n",
      " [  1.   1.   1.   1.   9.]]\n",
      "0.632\n",
      "0.368\n",
      "0.74\n",
      "0.764716981132\n"
     ]
    }
   ],
   "source": [
    "true_x = X_train[250000:250100]\n",
    "true_y = Y_train[250000:250100]\n",
    "pred_y = nbayes.predict(true_x)\n",
    "\n",
    "loss = np.full((5,5), 1.0)\n",
    "for i in range(len(pred_y)):\n",
    "    loss[pred_y[i], true_y[i]] += 1\n",
    "    \n",
    "TPR = loss.trace() / loss.sum()\n",
    "FNR = 1 - TPR\n",
    "\n",
    "print(loss)\n",
    "print(TPR)\n",
    "print(FNR)\n",
    "print(accuracy_score(pred_y, true_y))\n",
    "print(precision_score(pred_y, true_y, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### RANDOM TRAIN-TEST SPLIT\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "xx = X_train\n",
    "yy = Y_train\n",
    "\n",
    "param_grid = [\n",
    "  {\n",
    "        'n_gram': [1, 2, 3],\n",
    "        'laplace_smoothing': [1., 10.],\n",
    "        'cv_count_threshold': [0., 10., 25.]\n",
    "  }\n",
    " ]\n",
    "\n",
    "scoring = {'acc':        'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_micro':  'recall_macro'}\n",
    "\n",
    "def train_test_split_model(model, xxx, yyy, test_size=0.005):\n",
    "    xxx_train, xxx_test, yyy_train, yyy_test = train_test_split(xxx, yyy, test_size=test_size, random_state=0)\n",
    "    model.fit(xxx_train, yyy_train)\n",
    "    yyy_pred = model.predict(xxx_test)\n",
    "    return({\n",
    "            'test_accuracy': accuracy_score(yyy_test, yyy_pred),\n",
    "            'test_precision': precision_score(yyy_test, yyy_pred, average = 'macro'),\n",
    "            'test_recall': recall_score(yyy_test, yyy_pred, average = 'macro')\n",
    "           })\n",
    "\n",
    "tts_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_test_split_model(NaiveBayesClassifier(n_gram=2, laplace_smoothing=10., count_threshold=25), xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    k = \"n_gram={}\".format(i)\n",
    "    v = train_test_split_model(NaiveBayesClassifier(n_gram=i), xx, yy)\n",
    "    tts_scores[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [1., 10.]:\n",
    "    k = \"laplace_smoothing={}\".format(i)\n",
    "    v = train_test_split_model(NaiveBayesClassifier(laplace_smoothing=i), xx, yy)\n",
    "    tts_scores[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [1, 10, 25]:\n",
    "    k = \"count_threshold={}\".format(i)\n",
    "    v = train_test_split_model(NaiveBayesClassifier(count_threshold=i), xx, yy)\n",
    "    tts_scores[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_threshold=0.0</th>\n",
       "      <th>count_threshold=10.0</th>\n",
       "      <th>count_threshold=25.0</th>\n",
       "      <th>laplace_smoothing=1.0</th>\n",
       "      <th>laplace_smoothing=10.0</th>\n",
       "      <th>n_gram=1</th>\n",
       "      <th>n_gram=2</th>\n",
       "      <th>n_gram=3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>0.061372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.069191</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.096794</td>\n",
       "      <td>0.147704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.219355</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.245161</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count_threshold=0.0  count_threshold=10.0  \\\n",
       "test_accuracy              0.054152              0.054152   \n",
       "test_precision             0.075943              0.075943   \n",
       "test_recall                0.232258              0.232258   \n",
       "\n",
       "                count_threshold=25.0  laplace_smoothing=1.0  \\\n",
       "test_accuracy               0.054152               0.054152   \n",
       "test_precision              0.075943               0.075943   \n",
       "test_recall                 0.232258               0.232258   \n",
       "\n",
       "                laplace_smoothing=10.0  n_gram=1  n_gram=2  n_gram=3  \n",
       "test_accuracy                 0.050542  0.054152  0.057762  0.061372  \n",
       "test_precision                0.069191  0.075943  0.096794  0.147704  \n",
       "test_recall                   0.219355  0.232258  0.245161  0.258065  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tts_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853658536585\n",
      "0.146341463415\n",
      "cv_n_gram\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2c0620e1971b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                        \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                        \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                        return_train_score=True)\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0ma_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     cv_n_gram = pd.concat((cv_n_gram,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             return_times=True)\n\u001b[0;32m--> 195\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     99\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m    100\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32m<ipython-input-21-34ea3c0b7e50>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# Calculate likelihood for X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1998\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2000\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1926\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1927\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1929\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4009\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4010\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4011\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4013\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3895\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   3896\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 3897\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   3898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3899\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1046\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/algorithms.pyc\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1470\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### K FOLD IS TOO SLOW\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import random\n",
    "\n",
    "xx = X_train[:1000]\n",
    "yy = Y_train[:1000]\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'prec_macro': 'precision_macro',\n",
    "           'rec_micro': 'recall_macro'}\n",
    "\n",
    "print(\"cv_n_gram\")\n",
    "cv_n_gram = None\n",
    "for i in range(1, 3):\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(n_gram=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_n_gram = pd.concat((cv_n_gram,\n",
    "                           a_mean.rename(\"n_gram={}\".format(i))), axis=1)\n",
    "\n",
    "print(\"cv_laplace_smoothing\")\n",
    "cv_laplace_smoothing = None\n",
    "for i in [1., 5., 10.]:\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(laplace_smoothing=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_laplace_smoothing = pd.concat((cv_laplace_smoothing,\n",
    "                                      a_mean.rename(\"laplace_smoothing={}\".format(i))), axis=1)\n",
    "    \n",
    "print(\"cv_count_threshold\")\n",
    "cv_count_threshold = None\n",
    "for i in [0., 10., 25.]:\n",
    "    print(i)\n",
    "    a = cross_validate(NaiveBayesClassifier(count_threshold=i),\n",
    "                       xx,\n",
    "                       yy,\n",
    "                       fit_params={},\n",
    "                       scoring=scoring,\n",
    "                       cv=2,\n",
    "                       return_train_score=True)\n",
    "    a_mean = pd.DataFrame(a).mean(axis=0)\n",
    "    cv_count_threshold = pd.concat((cv_count_threshold,\n",
    "                                    a_mean.rename(\"count_threshold={}\".format(i))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cv_n_gram)\n",
    "print(cv_laplace_smoothing)\n",
    "print(cv_count_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
