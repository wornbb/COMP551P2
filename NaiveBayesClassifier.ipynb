{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self, use_uniform_prior = False, laplace_smoothing = 1.):\n",
    "        self.use_uniform_prior = use_uniform_prior\n",
    "        self.laplace_smoothing = laplace_smoothing # Bayesian prior for Naive Bayes of laplace_smoothing / 5\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        # Apply Laplace smoothing by adding a letter\n",
    "        X[X.columns[-5:]] += self.laplace_smoothing\n",
    "        # Count the # of n-grams observed in each language.\n",
    "        CY = np.array(X[X.columns[-5:]].apply(lambda x: np.sum(x) * 1., axis = 0).values)\n",
    "        # Define P(Y = y) as the proportion of n-grams observed in each language.\n",
    "        if self.use_uniform_prior:\n",
    "            PY = np.full(5, .1/5)\n",
    "        else:\n",
    "            PY = CY / np.sum(CY)\n",
    "        \n",
    "        # \"confusion\" function: predicted in rows, true in cols\n",
    "        confusion = np.zeros((5,5), float)\n",
    "        \n",
    "        for _, row in y.iterrows():\n",
    "            # Assume unigram for now\n",
    "            yi = [c for c in str(row['Text'])]\n",
    "            # Initialize P(X1 = x1, X2 = x2, ..., Xn = xn | Y = y)\n",
    "            PX_Y = np.array([1., 1., 1., 1., 1.])\n",
    "            # Numerically stable? # PX_Y_log = np.log(PX_Y)\n",
    "            # Calculate P(X1 = x1, X2 = x2, ..., Xn = xn | Y = y) = prod_i P(Xi = xi | Y = y)\n",
    "            for yil in yi:\n",
    "                # Calculate P(X1 = x1 | Y = y)\n",
    "                if yil in X.index:\n",
    "                    Px_Y = None\n",
    "                    Px_Y = X[X.index == yil][:1].reset_index().values\n",
    "                    Px_Y = np.delete(Px_Y, 0).astype(float)\n",
    "                    Px_Y = np.array(Px_Y)\n",
    "                else:\n",
    "                    continue # ignore unknown n-grams\n",
    "                # Obtain P(X = x | Y = y) by calculating per-category frequency\n",
    "                # of current letter\n",
    "                Px_Y = Px_Y / CY\n",
    "                # Push to accumulator.\n",
    "                PX_Y = np.multiply(PX_Y, Px_Y)\n",
    "                # Numerically stable? # PX_Y_log = PX_Y_log + np.log(Px_Y)\n",
    "            # Throw in prior: P(X... | Y = y)P(Y)\n",
    "            PX_Y_PY = np.multiply(PX_Y, PY)\n",
    "            # Get the posterior: P(Y|X) = P(X|Y) P(Y)/P(X)\n",
    "            # where P(X) = sum_i P(X... | Y = y_i)P(Y_i) and use\n",
    "            PY_X = PX_Y_PY / np.sum(PX_Y_PY)\n",
    "            \n",
    "            pred_label = PY_X.argmax()\n",
    "            true_label = row['Category']\n",
    "            \n",
    "            confusion[pred_label, true_label] += 1\n",
    "            \n",
    "        print(confusion)\n",
    "        loss_score = (np.trace(confusion) / np.sum(confusion))\n",
    "        print(loss_score)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        return []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nbayes__laplace_smoothing': 0.1, 'nbayes': NaiveBayesClassifier(laplace_smoothing=0.1, use_uniform_prior=False), 'ngram': <NGramGenerator.NGramGenerator object at 0x10fa83d10>, 'nbayes__use_uniform_prior': False, 'memory': None, 'steps': [('ngram', <NGramGenerator.NGramGenerator object at 0x10fa83d10>), ('nbayes', NaiveBayesClassifier(laplace_smoothing=0.1, use_uniform_prior=False))]}\n",
      "[[ 11.   0.   3.   0.   0.]\n",
      " [  0.  93.  15.   4.   1.]\n",
      " [  0.  14.  26.   1.   1.]\n",
      " [  0.   3.   0.  22.   1.]\n",
      " [  0.   0.   1.   0.   4.]]\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from NGramGenerator import *\n",
    "\n",
    "Xf = pd.read_csv(\"data/train_set_x.csv\")\n",
    "T  = pd.read_csv(\"data/train_set_y.csv\")\n",
    "X  = pd.merge(Xf, T, on = 'Id')\n",
    "Y  = pd.read_csv(\"data/test_set_x.csv\")\n",
    "\n",
    "ngram = NGramGenerator(1, True, 0, False)\n",
    "nbayes = NaiveBayesClassifier()\n",
    "\n",
    "p = Pipeline(\n",
    "    [( 'ngram', ngram )] +\n",
    "    [( 'nbayes', nbayes )]\n",
    ")\n",
    "\n",
    "p.set_params(nbayes__use_uniform_prior = False)\n",
    "p.set_params(nbayes__laplace_smoothing = .1)\n",
    "print(p.get_params())\n",
    "A = p.fit_transform(X[:1000], X[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
